{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Project Notebook <center>\n",
    "    \n",
    "### <center>Streaming Services vs Car Manufacturers<center>\n",
    "\n",
    "<center>This project will analyse 2 portfolios to find out which one it the best portfolio for our client.<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this project, we will be using as reference the beggining of 2016. We will be considering a customer with a budget to invest $100k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading Stock Data from Yahoo Finance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get acces to the stock price data, we will be using the yahoo finance library, that provides the date (as index), Close Price, Open Price, Adjusted Close Price, High,Low, and the Volume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "## Importing yahoo finance library\n",
    "import yfinance as yf\n",
    "\n",
    "## Streaming services stock price data\n",
    "NFLX = yf.download('NFLX',start = '2016-01-01', end = '2020-12-31')\n",
    "AAPL = yf.download('AAPL',start = '2016-01-01', end = '2020-12-31')\n",
    "DIS = yf.download('DIS',start = '2016-04-03', end = '2020-12-31')\n",
    "SPOT = yf.download('SPOT',start = '2016-01-01', end = '2020-12-31')\n",
    "AMZN = yf.download('AMZN',start = '2016-01-01', end = '2020-12-31')\n",
    "\n",
    "## Car manufacturers stock price data\n",
    "FORD = yf.download('F',start = '2016-01-01', end = '2020-12-31')\n",
    "TSLA = yf.download('TSLA',start = '2016-01-01', end = '2020-12-31')\n",
    "TOYOTA = yf.download('TM',start = '2016-01-01', end = '2020-12-31')\n",
    "FERRARI = yf.download('RACE',start = '2016-01-01', end = '2020-12-31')\n",
    "FIAT = yf.download('FCAU',start = '2016-01-01', end = '2020-12-31')\n",
    "\n",
    "# Downloading S&P 500/benchmark stock price data\n",
    "sp = yf.download('^GSPC', start = '2016-01-01', end = '2020-12-31')\n",
    "\n",
    "\n",
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating One Portfolio for Each Company Category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Total Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_streaming = pd.DataFrame({\n",
    "    'NFLX_tot_return' : NFLX['Adj Close'].pct_change(),\n",
    "    'AAPL_tot_return' : AAPL['Adj Close'].pct_change(),\n",
    "    'DIS_tot_return' : DIS['Adj Close'].pct_change(),\n",
    "    'SPOT_tot_return' : SPOT['Adj Close'].pct_change(),\n",
    "    'AMZN_tot_return' : AMZN['Adj Close'].pct_change()\n",
    "})\n",
    "portfolio_streaming = portfolio_streaming.dropna()\n",
    "portfolio_manufacturers = pd.DataFrame({\n",
    "    'FORD_tot_return' : FORD['Adj Close'].pct_change(),\n",
    "    'FERRARI_tot_return' : FERRARI['Adj Close'].pct_change(),\n",
    "    'TSLA_tot_return' : TSLA['Adj Close'].pct_change(),\n",
    "    'TOYOTA_tot_return' : TOYOTA['Adj Close'].pct_change(),\n",
    "    'FIAT_tot_return' : FIAT['Adj Close'].pct_change()\n",
    "})\n",
    "portfolio_manufacturers = portfolio_manufacturers.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_portfolio = pd.DataFrame({\n",
    "    'FORD_tot_return' : FORD['Adj Close'].pct_change(),\n",
    "    'FERRARI_tot_return' : FERRARI['Adj Close'].pct_change(),\n",
    "    'TSLA_tot_return' : TSLA['Adj Close'].pct_change(),\n",
    "    'TOYOTA_tot_return' : TOYOTA['Adj Close'].pct_change(),\n",
    "    'FIAT_tot_return' : FIAT['Adj Close'].pct_change(),\n",
    "    'NFLX_tot_return' : NFLX['Adj Close'].pct_change(),\n",
    "    'AAPL_tot_return' : AAPL['Adj Close'].pct_change(),\n",
    "    'DIS_tot_return' : DIS['Adj Close'].pct_change(),\n",
    "    'SPOT_tot_return' : SPOT['Adj Close'].pct_change(),\n",
    "    'AMZN_tot_return' : AMZN['Adj Close'].pct_change()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimizing variance\n",
    "\n",
    "Here we will compute the portfolio percentage that would give the lowest portfolio variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX:  8.653 %\n",
      "AAPL:  8.804 %\n",
      "DIS:  41.212 %\n",
      "SPOT:  10.819 %\n",
      "AMZN:  30.511 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio variance\n",
    "def minimum_variance(x, cov_matrix):\n",
    "    f=float(np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "## Defining the number of stocks\n",
    "n=portfolio_streaming.shape[1]\n",
    "\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = portfolio_streaming.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_mv = minimize(minimum_variance, x, \n",
    "                     args = (cov_matrix),method = 'SLSQP', \n",
    "                     bounds = bounds, constraints = cons)\n",
    "\n",
    "print('NFLX: ',round(result_mv['x'][0]*100,3),'%')\n",
    "print('AAPL: ',round(result_mv['x'][1]*100,3),'%')\n",
    "print('DIS: ',round(result_mv['x'][2]*100,3),'%')\n",
    "print('SPOT: ',round(result_mv['x'][3]*100,3),'%')\n",
    "print('AMZN: ',round(result_mv['x'][4]*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Car Manufacturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORD:  2.988 %\n",
      "FERRARI:  14.559 %\n",
      "TSLA:  2.093 %\n",
      "TOYOTA:  80.361 %\n",
      "FIAT:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio variance\n",
    "def minimum_variance(x, cov_matrix):\n",
    "    f=float(np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "## Defining the number of stocks\n",
    "n=portfolio_manufacturers.shape[1]\n",
    "\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = portfolio_manufacturers.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_mv = minimize(minimum_variance, x, \n",
    "                     args = (cov_matrix),method = 'SLSQP', \n",
    "                     bounds = bounds, constraints = cons)\n",
    "\n",
    "print('FORD: ',round(result_mv['x'][0]*100,3),'%')\n",
    "print('FERRARI: ',round(result_mv['x'][1]*100,3),'%')\n",
    "print('TSLA: ',round(result_mv['x'][2]*100,3),'%')\n",
    "print('TOYOTA: ',round(result_mv['x'][3]*100,3),'%')\n",
    "print('FIAT: ',round(result_mv['x'][4]*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximizing Sharpe Ratio\n",
    "\n",
    "Here we will find out which is the portfolio percentage needed to reach the highest Sharpe Ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX:  0.0 %\n",
      "AAPL:  62.368 %\n",
      "DIS:  10.147 %\n",
      "SPOT:  13.227 %\n",
      "AMZN:  14.258 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio Sharpe Ratio\n",
    "def sharpe_ratio(x, cov_matrix, mean_vector, r_f):\n",
    "    f=float(-(x.dot(mean_vector)-r_f)/np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "\n",
    "## Defining the risk free rate\n",
    "daily_risk = 0.0008 / 365\n",
    "\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the mean portfolio_streaming\n",
    "mean_vector = np.mean(portfolio_streaming, axis=0)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = portfolio_streaming.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_Sharpe = minimize(sharpe_ratio, x,\n",
    "                         args=(cov_matrix, mean_vector, daily_risk),\n",
    "                         method = 'SLSQP', bounds = bounds,\n",
    "                         constraints = cons).x\n",
    "print('NFLX: ',round(result_Sharpe[0]*100,3),'%')\n",
    "print('AAPL: ',round(result_Sharpe[1]*100,3),'%')\n",
    "print('DIS: ',round(result_Sharpe[2]*100,3),'%')\n",
    "print('SPOT: ',round(result_Sharpe[3]*100,3),'%')\n",
    "print('AMZN: ',round(result_Sharpe[4]*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Car Manufacturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORD:  0.0 %\n",
      "FERRARI:  62.869 %\n",
      "TSLA:  37.131 %\n",
      "TOYOTA:  0.0 %\n",
      "FIAT:  0.0 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio Sharpe Ratio\n",
    "def sharpe_ratio(x, cov_matrix, mean_vector, r_f):\n",
    "    f=float(-(x.dot(mean_vector)-r_f)/np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "\n",
    "## Defining the risk free rate\n",
    "daily_risk = 0.0008 / 365\n",
    "\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the mean portfolio_manufacturers\n",
    "mean_vector = np.mean(portfolio_manufacturers, axis=0)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = portfolio_manufacturers.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_Sharpe = minimize(sharpe_ratio, x,\n",
    "                        args=(cov_matrix, mean_vector, daily_risk),\n",
    "                        method = 'SLSQP', bounds = bounds,\n",
    "                        constraints = cons).x\n",
    "print('FORD: ',round(result_Sharpe[0]*100,3),'%')\n",
    "print('FERRARI: ',round(result_Sharpe[1]*100,3),'%')\n",
    "print('TSLA: ',round(result_Sharpe[2]*100,3),'%')\n",
    "print('TOYOTA: ',round(result_Sharpe[3]*100,3),'%')\n",
    "print('FIAT: ',round(result_Sharpe[4]*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gross Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_streaming['Benchmark_tot_return'] = sp['Adj Close'].pct_change()\n",
    "portfolio_streaming = portfolio_streaming.dropna()\n",
    "portfolio_manufacturers['Benchmark_tot_return'] = sp['Adj Close'].pct_change()\n",
    "portfolio_manufacturers = portfolio_manufacturers.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Streaming gross profit\n",
    "portfolio_streaming['NFLX_gross_return'] = 1 + portfolio_streaming['NFLX_tot_return']\n",
    "portfolio_streaming['AAPL_gross_return'] = 1 + portfolio_streaming['AAPL_tot_return']\n",
    "portfolio_streaming['DIS_gross_return'] = 1 + portfolio_streaming['DIS_tot_return']\n",
    "portfolio_streaming['SPOT_gross_return'] = 1 + portfolio_streaming['SPOT_tot_return']\n",
    "portfolio_streaming['AMZN_gross_return'] = 1 + portfolio_streaming['AMZN_tot_return']\n",
    "\n",
    "## Manufacturers gross profit\n",
    "portfolio_manufacturers['FORD_gross_return'] = 1 + portfolio_manufacturers['FORD_tot_return']\n",
    "portfolio_manufacturers['FERRARI_gross_return']= 1 + portfolio_manufacturers['FERRARI_tot_return']\n",
    "portfolio_manufacturers['TSLA_gross_return']= 1 + portfolio_manufacturers['TSLA_tot_return']\n",
    "portfolio_manufacturers['TOYOTA_gross_return']= 1 +  portfolio_manufacturers['TOYOTA_tot_return']\n",
    "portfolio_manufacturers['FIAT_gross_return']= 1 +  portfolio_manufacturers['FIAT_tot_return']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cumulative Returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dropping null values\n",
    "portfolio_streaming = portfolio_streaming.dropna()\n",
    "portfolio_manufacturers = portfolio_manufacturers.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Streaming cumulative returns\n",
    "portfolio_streaming['NFLX_cum_return'] = portfolio_streaming['NFLX_gross_return'].cumprod()\n",
    "portfolio_streaming['AAPL_cum_return'] = portfolio_streaming['AAPL_gross_return'].cumprod()\n",
    "portfolio_streaming['DIS_cum_return'] = portfolio_streaming['DIS_gross_return'].cumprod()\n",
    "portfolio_streaming['SPOT_cum_return'] = portfolio_streaming['SPOT_gross_return'].cumprod()\n",
    "portfolio_streaming['AMZN_cum_return'] = portfolio_streaming['AMZN_gross_return'].cumprod()\n",
    "\n",
    "## Manufacturers cumulative returns\n",
    "portfolio_manufacturers['FORD_cum_return'] = portfolio_manufacturers['FORD_gross_return'].cumprod()\n",
    "portfolio_manufacturers['FERRARI_cum_return'] = portfolio_manufacturers['FERRARI_gross_return'].cumprod()\n",
    "portfolio_manufacturers['TSLA_cum_return'] = portfolio_manufacturers['TSLA_gross_return'].cumprod()\n",
    "portfolio_manufacturers['TOYOTA_cum_return'] = portfolio_manufacturers['TOYOTA_gross_return'].cumprod()\n",
    "portfolio_manufacturers['FIAT_cum_return'] = portfolio_manufacturers['FIAT_gross_return'].cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Weighted Portfoliios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it is hard to decide a percentage of investment for each security in the portfolio, we decided to create a model to test different combinations of percentage. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Random\" choices are not good when looking at stocks, but the purpose of the model is to test different percentages combinations that return the highest amount of money for the investor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight Performance Indicator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Random Weights for Streaming Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of lists you want to generate: 100000\n",
      "NFLX: % 17.27\n",
      "AAPL: % 28.69\n",
      "DIS: % 18.79\n",
      "SPOT: % 17.3\n",
      "AMZN: % 17.95\n",
      "\n",
      "Streaming Portfolio Return: % 240.91\n"
     ]
    }
   ],
   "source": [
    "## Creating empty list\n",
    "random_weights = []\n",
    "\n",
    "## Here we create the number of lists we want to create to simulate differnt portfolios\n",
    "n = int(input('Enter number of lists you want to generate: '))\n",
    "\n",
    "## Creating n lists in the array of lists\n",
    "for p in range(n):\n",
    "    ## Here we create a list with 5 random numbers that sum up to 1.0 (no negative numbers)\n",
    "    random_weights.append(np.random.uniform(low=0.15,high=0.25,size=5))\n",
    "    random_weights[p] /= random_weights[p].sum()\n",
    "    \n",
    "## Here we print the array of lists\n",
    "#print(random_weights)\n",
    "\n",
    "## Creating variable to hold maximum return\n",
    "str_maximum = 0\n",
    "\n",
    "## Variable to hold the list used to generate best performing weights\n",
    "str_weights = 0\n",
    "\n",
    "## New column to hold histoical data with best final performance\n",
    "portfolio_streaming['modeling_returns'] = 0\n",
    "\n",
    "## Here we go through the n number of lists in the array of lists\n",
    "for i in range(n):\n",
    "    \n",
    "    ## Here we go through the 5 indexes of each list\n",
    "    streaming_return = random_weights[i][0]*portfolio_streaming['NFLX_cum_return'] \\\n",
    "    + random_weights[i][1]*portfolio_streaming['AAPL_cum_return']\\\n",
    "    + random_weights[i][2]*portfolio_streaming['DIS_cum_return']\\\n",
    "    + random_weights[i][3]*portfolio_streaming['SPOT_cum_return']\\\n",
    "    + random_weights[i][4]*portfolio_streaming['AMZN_cum_return']\n",
    "    ## Here we print the weights used for each calculation\n",
    "    #print('Weights: %',random_weights[i])\n",
    "    ## Here we return the best performance \n",
    "    if streaming_return.tail()[-1] > str_maximum: \n",
    "        str_maximum = streaming_return.tail()[-1]    \n",
    "            \n",
    "        ## Adding weights of the maximum value to the weights list\n",
    "        str_weights = random_weights[i]\n",
    "\n",
    "        ## Add data to new data frame column\n",
    "        portfolio_streaming['modeling_returns'] = streaming_return\n",
    "        \n",
    "    #print('')\n",
    "    ## Here we print the returns result for each list in the array\n",
    "    #print('Return %:',round(streaming_return.tail()[-1]*100,2))\n",
    "    #print('')\n",
    "\n",
    "print('NFLX: %', round(str_weights[0]*100,2))\n",
    "print('AAPL: %', round(str_weights[1]*100,2))\n",
    "print('DIS: %', round(str_weights[2]*100,2))\n",
    "print('SPOT: %', round(str_weights[3]*100,2))\n",
    "print('AMZN: %', round(str_weights[4]*100,2))\n",
    "print('')\n",
    "print('Streaming Portfolio Return: %',round(str_maximum*100,2))\n",
    "## Visualize new column\n",
    "#print(portfolio_streaming['modeling_returns'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Money received from each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return Netflix: $ 31945.27\n",
      "Return Apple: $ 94315.53\n",
      "Return Disney: $ 35212.06\n",
      "Return Spotify: $ 37066.01\n",
      "Return Amazon: $ 42367.25\n",
      " \n",
      "Sum Streaming Portfolio Return: $ 240906.12\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Return Netflix: $',round(str_weights[0]*portfolio_streaming['NFLX_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Apple: $',round(str_weights[1]*portfolio_streaming['AAPL_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Disney: $',round(str_weights[2]*portfolio_streaming['DIS_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Spotify: $',round(str_weights[3]*portfolio_streaming['SPOT_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Amazon: $',round(str_weights[4]*portfolio_streaming['AMZN_cum_return'].tail()[-1]*100000,2))\n",
    "print(' ')\n",
    "print(print('Sum Streaming Portfolio Return: $',round(str_maximum*100000,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted streaming portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted streaming % 164.53341\n"
     ]
    }
   ],
   "source": [
    "## Creating weights manualy\n",
    "weight1 = 0.2\n",
    "weight2 = 0.2\n",
    "weight3 = 0.2\n",
    "weight4 = 0.2\n",
    "weight5 = 0.2\n",
    "\n",
    "## Creating weighted portfolio\n",
    "portfolio_streaming_weighted_returns = weight1*portfolio_streaming['NFLX_cum_return']\\\n",
    "    + weight3*portfolio_streaming['DIS_cum_return']\\\n",
    "    + weight4*portfolio_streaming['SPOT_cum_return']\\\n",
    "    + weight5*portfolio_streaming['AMZN_cum_return']\n",
    "\n",
    "## Printing the results with 2 decimals\n",
    "print('Weighted streaming','%',round(portfolio_streaming_weighted_returns.tail()[-1]*100,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing Random Weights for Manufacturers Portfolio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Weight Performance Indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of lits you want to generate: 1000\n",
      "FORD: % 17.44\n",
      "FERRARI: % 17.23\n",
      "TSLA: % 27.08\n",
      "FIAT: % 18.83\n",
      "TOYOTA: % 19.43\n",
      "\n",
      "Manufacturers Portfolio Return: % 596.62\n"
     ]
    }
   ],
   "source": [
    "## Creating empty list\n",
    "random_weights = []\n",
    "\n",
    "## Here we create the number of lists we want to create to simulate differnt portfolios\n",
    "n = int(input('Enter number of lits you want to generate: '))\n",
    "\n",
    "## Here we define the number of lists we want to create\n",
    "for p in range(n):\n",
    "    ## Here we create a list with 5 float numbers that sum to 1 (random numbers goes from 0.0 to 1.0)\n",
    "    \n",
    "    ## Here we create a low of 15% and high of 25% (weights for portfolio)\n",
    "    ## Size creates a list of 5 numbers\n",
    "    random_weights.append(np.random.uniform(low=0.15,high=0.25,size=5)) \n",
    "    \n",
    "    ## Here we ensure the sum of the numbers in the list equal to 1 (100%)\n",
    "    random_weights[p] /= random_weights[p].sum()\n",
    "    \n",
    "    \n",
    "## Here we check the results\n",
    "#print(random_weights)\n",
    "\n",
    "## Creating variable to hold best return possible\n",
    "mtr_maximum =  0\n",
    "\n",
    "## Creating variable to hold results of best weights\n",
    "mtr_weights = 0\n",
    "\n",
    "##Variable to hold returns with highest final return\n",
    "portfolio_manufacturers['modeling_returns'] = 0\n",
    "## Here we go through each index of the array of lists\n",
    "## The range should be <= to the previous range used to create the lists\n",
    "## The higher the n, the more simulations, and more accurate the results will be.\n",
    "for i in range(n):\n",
    "    ## Here we use each list and each value to caluclate the returns\n",
    "    manufacturers_return = random_weights[i][0]* portfolio_manufacturers['FORD_cum_return'] \\\n",
    "    + random_weights[i][1]*portfolio_manufacturers['FERRARI_cum_return']\\\n",
    "    + random_weights[i][2]*portfolio_manufacturers['TSLA_cum_return']\\\n",
    "    + random_weights[i][3]*portfolio_manufacturers['TOYOTA_cum_return']\\\n",
    "    +random_weights[i][4]*portfolio_manufacturers['FIAT_cum_return']\n",
    "        \n",
    "    ## Here we print the weights used for each simulation\n",
    "    #print('Weights: %',round(random_weights[i][j]*100,1))\n",
    "    \n",
    "    ## Here we will return the highest return possible\n",
    "    if manufacturers_return.tail()[-1] > mtr_maximum: \n",
    "        mtr_maximum = manufacturers_return.tail()[-1]\n",
    "        ## Here we return the weights used to reach the highest return\n",
    "        mtr_weights = random_weights[i]\n",
    "        \n",
    "        ## Here we create the best return performance data\n",
    "        portfolio_manufacturers['modeling_returns'] = manufacturers_return\n",
    "        \n",
    "        \n",
    "    #print('')\n",
    "    ## Printing results for each list\n",
    "    #print('Returns: %',round(manufacturers_return.tail()[-1]*100,2))\n",
    "    #print('')\n",
    "\n",
    "## Here we print the results of the weights\n",
    "#print('Weights list =',mtr_weights)\n",
    "\n",
    "## Here we print the weight separately for each company\n",
    "print('FORD: %', round(mtr_weights[0]*100,2))\n",
    "print('FERRARI: %', round(mtr_weights[1]*100,2))\n",
    "print('TSLA: %', round(mtr_weights[2]*100,2))\n",
    "print('FIAT: %', round(mtr_weights[3]*100,2))\n",
    "print('TOYOTA: %', round(mtr_weights[4]*100,2))\n",
    "print('')\n",
    "print('Manufacturers Portfolio Return: %',round(mtr_maximum*100,2))\n",
    "## Visualize new column\n",
    "#print(portfolio_manufacturers['modeling_returns'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Money received from each stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return Ford: $ 14523.12\n",
      "Return Ferrari: $ 87371.29\n",
      "Return Tesla: $ 421145.45\n",
      "Return Fiat: $ 47365.03\n",
      "Return Toyota: $ 25492.09\n",
      " \n",
      "Sum manufacturer Portfolio Return: $ 596619.27\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Return Ford: $',round(mtr_weights[0]*portfolio_manufacturers['FORD_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Ferrari: $',round(mtr_weights[1]*portfolio_manufacturers['FERRARI_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Tesla: $',round(mtr_weights[2]*portfolio_manufacturers['TSLA_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Fiat: $',round(mtr_weights[3]*portfolio_manufacturers['FIAT_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Toyota: $',round(mtr_weights[4]*portfolio_manufacturers['TOYOTA_cum_return'].tail()[-1]*100000,2))\n",
    "print(' ')\n",
    "print(print('Sum manufacturer Portfolio Return: $',round(mtr_maximum*100000,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Weighted Manufacturers Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted manufacturers % 505.65\n"
     ]
    }
   ],
   "source": [
    "## Creating te weights manually\n",
    "w1 = 0.20\n",
    "w2 = 0.20\n",
    "w3 = 0.20\n",
    "w4 = 0.20\n",
    "w5 = 0.20\n",
    "\n",
    "## Applying the weights for each stock\n",
    "portfolio_manufacturers_weighted_returns = w1* portfolio_manufacturers['FORD_cum_return']\\\n",
    "    + w2*portfolio_manufacturers['FERRARI_cum_return']\\\n",
    "    + w3*portfolio_manufacturers['TSLA_cum_return']\\\n",
    "    + w4*portfolio_manufacturers['TOYOTA_cum_return']\\\n",
    "    + w5*portfolio_manufacturers['FIAT_cum_return']\n",
    "\n",
    "## Printing the results\n",
    "print('Weighted manufacturers','%',round(portfolio_manufacturers_weighted_returns.tail()[-1]*100,2))                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Streaming Portfolio Return: % 240.91\n",
      "\n",
      "Weighted Portfolio streaming: % 164.53\n",
      "\n",
      "Manufacturers Portfolio Return: % 596.62\n",
      "\n",
      "Weighted Portfolio Manufacturers: % 505.65\n"
     ]
    }
   ],
   "source": [
    "print('Streaming Portfolio Return: %', round(str_maximum*100,2))\n",
    "print('')\n",
    "print('Weighted Portfolio streaming: %',round(portfolio_streaming_weighted_returns.tail()[-1]*100,2))\n",
    "print('')\n",
    "print('Manufacturers Portfolio Return: %',round(mtr_maximum*100,2))\n",
    "print('')\n",
    "print('Weighted Portfolio Manufacturers: %',round(portfolio_manufacturers_weighted_returns.tail()[-1]*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ES and vaR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Streaming Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 5% chance that the portfolio losses will exceed $1326.32 dollars.\n",
      "If the losses exceed this value, there is a 5% chance that the losses will average $1899.72 dollars.\n"
     ]
    }
   ],
   "source": [
    "## Computing the value of the investment\n",
    "NFLX_current_value = str_weights[0]*100000*portfolio_streaming['NFLX_cum_return'][-1]\n",
    "AAPL_current_value = str_weights[1]*100000*portfolio_streaming['AAPL_tot_return'][-1]\n",
    "DIS_current_value = str_weights[2]*100000*portfolio_streaming['DIS_tot_return'][-1]\n",
    "SPOT_current_value = str_weights[3]*100000*portfolio_streaming['SPOT_tot_return'][-1]\n",
    "AMZN_current_value = str_weights[4]*100000*portfolio_streaming['AMZN_tot_return'][-1]\n",
    "\n",
    "\n",
    "## Calculating sim portfolio\n",
    "sim_portfolio_stream = NFLX_current_value*portfolio_streaming['NFLX_tot_return'] \\\n",
    "+AAPL_current_value*portfolio_streaming['AAPL_tot_return']\\\n",
    "+DIS_current_value*portfolio_streaming['DIS_tot_return']\\\n",
    "+SPOT_current_value*portfolio_streaming['SPOT_tot_return']\\\n",
    "+AMZN_current_value*portfolio_streaming['AMZN_tot_return']\n",
    "\n",
    "## Calculating Value at Risk (vaR)\n",
    "vaR_str = np.percentile(sim_portfolio_stream,5)\n",
    "\n",
    "## Calculating ES\n",
    "ES_str = sim_portfolio_stream[sim_portfolio_stream<vaR_str].mean()\n",
    "\n",
    "print('There is a 5% chance that the portfolio losses will exceed ${} dollars.'.format(round(vaR_str*-1,2)))\n",
    "print('If the losses exceed this value, there is a 5% chance that the losses will average ${} dollars.'.format(round(ES_str*-1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Car Manufacturers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 5% chance that the portfolio losses will exceed $453.17 dollars.\n",
      "If the losses exceed this value, there is a 5% chance that the losses will average $757.79 dollars.\n"
     ]
    }
   ],
   "source": [
    "## Computing the value of the investment\n",
    "FORD_current_value = mtr_weights[0]*100000*portfolio_manufacturers['FORD_cum_return'][-1]\n",
    "FERRARI_current_value = mtr_weights[1]*100000*portfolio_manufacturers['FERRARI_tot_return'][-1]\n",
    "TSLA_current_value = mtr_weights[2]*100000*portfolio_manufacturers['TSLA_tot_return'][-1]\n",
    "TOYOTA_current_value = mtr_weights[3]*100000*portfolio_manufacturers['TOYOTA_tot_return'][-1]\n",
    "FIAT_current_value = mtr_weights[4]*100000*portfolio_manufacturers['FIAT_tot_return'][-1]\n",
    "\n",
    "\n",
    "## Calculating sim portfolio\n",
    "sim_portfolio_stream =FORD_current_value*portfolio_manufacturers['FORD_tot_return'] \\\n",
    "+FERRARI_current_value*portfolio_manufacturers['FERRARI_tot_return']\\\n",
    "+TSLA_current_value*portfolio_manufacturers['TSLA_tot_return']\\\n",
    "+TOYOTA_current_value*portfolio_manufacturers['TOYOTA_tot_return']\n",
    "\n",
    "## Calculating Value at Risk (vaR_mtr)\n",
    "vaR_mtr = np.percentile(sim_portfolio_stream,5)\n",
    "\n",
    "## Calculating ES\n",
    "ES_mtr = sim_portfolio_stream[sim_portfolio_stream<vaR_mtr].mean()\n",
    "\n",
    "print('There is a 5% chance that the portfolio losses will exceed ${} dollars.'.format(round(vaR_mtr*-1,2)))\n",
    "print('If the losses exceed this value, there is a 5% chance that the losses will average ${} dollars.'.format(round(ES_mtr*-1,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vaR streaming: $ 1326.316\n",
      "vaR manufacturers: $ 514.871\n"
     ]
    }
   ],
   "source": [
    "print('vaR streaming: $',round(vaR_str*-1,3))\n",
    "print('vaR manufacturers: $',round(vaR_mtr*-1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ES streaming: $ 1899.723\n",
      "ES manufacturers: $ 854.633\n"
     ]
    }
   ],
   "source": [
    "print('ES streaming: $',round(ES_str*-1,3))\n",
    "print('ES manufacturers: $',round(ES_mtr*-1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharpe Ratio "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Streaming Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe values\n",
      " \n",
      "Portfolio:3.843\n",
      "Benchmark:0.046\n"
     ]
    }
   ],
   "source": [
    "## Computing the Sharpe Ratio of the portfolio\n",
    "daily_risk_free = 0.0008 / 365\n",
    "mu_portfolio_1 = portfolio_streaming['modeling_returns'].mean()\n",
    "sd_portfolio_1 = portfolio_streaming['modeling_returns'].std()\n",
    "Sharpe_Portfolio_1 = (mu_portfolio_1 - daily_risk_free) / sd_portfolio_1\n",
    "\n",
    "## Computing the Sharpe Ratio of the benchmark\n",
    "mu_benchmark = sp['Adj Close'].pct_change().mean()\n",
    "sd_benchmark = sp['Adj Close'].pct_change().std()\n",
    "Sharpe_Benchmark = (mu_benchmark - daily_risk_free) / sd_benchmark\n",
    "\n",
    "print('Sharpe values')\n",
    "print(' ')\n",
    "print('Portfolio:{}'.format(round(Sharpe_Portfolio_1, 3)))\n",
    "print('Benchmark:{}'.format(round(Sharpe_Benchmark, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Car Manufacturers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe values\n",
      " \n",
      "Portfolio:1.9\n",
      "Benchmark:0.046\n"
     ]
    }
   ],
   "source": [
    "## Computing the Sharpe Ratio of the portfolio\n",
    "daily_risk_free = 0.0008 / 365\n",
    "mu_portfolio_2 = portfolio_manufacturers['modeling_returns'].mean()\n",
    "sd_portfolio_2 = portfolio_manufacturers['modeling_returns'].std()\n",
    "Sharpe_Portfolio_2 = (mu_portfolio_2 - daily_risk_free) / sd_portfolio_2\n",
    "\n",
    "## Computing the Sharpe Ratio of the benchmark\n",
    "mu_benchmark = sp['Adj Close'].pct_change().mean()\n",
    "sd_benchmark = sp['Adj Close'].pct_change().std()\n",
    "Sharpe_Benchmark = (mu_benchmark - daily_risk_free) / sd_benchmark\n",
    "\n",
    "print('Sharpe values')\n",
    "print(' ')\n",
    "print('Portfolio:{}'.format(round(Sharpe_Portfolio_2, 3)))\n",
    "print('Benchmark:{}'.format(round(Sharpe_Benchmark, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both portfolios have outperformed the benchmark, but the Streaming Services has a higher Sharpe Ratio than the Car Manufacturer portfolio. \n",
    "\n",
    "**A higher Sharp Ratio is preferred.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each stock, we will compute the Garman Klass volatility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stream Services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "NFLX['log_high_low'] = np.log(NFLX['High'] / NFLX['Low'])\n",
    "NFLX['log_high_low_square'] = NFLX['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "NFLX['log_close_open'] = np.log(NFLX['Close'] / NFLX['Open'])\n",
    "NFLX['log_close_open_square'] = NFLX['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_NFLX = np.sqrt((1/(2*NFLX.shape[0]))*\n",
    "                       np.sum(NFLX['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/NFLX.shape[0])*\n",
    "                              NFLX['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "AAPL['log_high_low'] = np.log(AAPL['High'] / AAPL['Low'])\n",
    "AAPL['log_high_low_square'] = AAPL['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "AAPL['log_close_open'] = np.log(AAPL['Close'] / AAPL['Open'])\n",
    "AAPL['log_close_open_square'] = AAPL['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_AAPL = np.sqrt((1/(2*AAPL.shape[0]))*\n",
    "                       np.sum(AAPL['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/AAPL.shape[0])*\n",
    "                              AAPL['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "DIS['log_high_low'] = np.log(DIS['High'] / DIS['Low'])\n",
    "DIS['log_high_low_square'] = DIS['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "DIS['log_close_open'] = np.log(DIS['Close'] / DIS['Open'])\n",
    "DIS['log_close_open_square'] = DIS['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_DIS= np.sqrt((1/(2*DIS.shape[0]))*\n",
    "                       np.sum(DIS['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/DIS.shape[0])*\n",
    "                              DIS['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "SPOT['log_high_low'] = np.log(SPOT['High'] / SPOT['Low'])\n",
    "SPOT['log_high_low_square'] = SPOT['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "SPOT['log_close_open'] = np.log(SPOT['Close'] / SPOT['Open'])\n",
    "SPOT['log_close_open_square'] = SPOT['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_SPOT = np.sqrt((1/(2*SPOT.shape[0]))*\n",
    "                       np.sum(SPOT['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/SPOT.shape[0])*\n",
    "                              SPOT['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "AMZN['log_high_low'] = np.log(AMZN['High'] / AMZN['Low'])\n",
    "AMZN['log_high_low_square'] = AMZN['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "AMZN['log_close_open'] = np.log(AMZN['Close'] / AMZN['Open'])\n",
    "AMZN['log_close_open_square'] = AMZN['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_AMZN = np.sqrt((1/(2*AMZN.shape[0]))*\n",
    "                       np.sum(AMZN['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/AMZN.shape[0])*\n",
    "                              AMZN['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "FORD['log_high_low'] = np.log(FORD['High'] / FORD['Low'])\n",
    "FORD['log_high_low_square'] = FORD['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "FORD['log_close_open'] = np.log(FORD['Close'] / FORD['Open'])\n",
    "FORD['log_close_open_square'] = FORD['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_FORD = np.sqrt((1/(2*FORD.shape[0]))*\n",
    "                       np.sum(FORD['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/FORD.shape[0])*\n",
    "                              FORD['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "FERRARI['log_high_low'] = np.log(FERRARI['High'] / FERRARI['Low'])\n",
    "FERRARI['log_high_low_square'] = FERRARI['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "FERRARI['log_close_open'] = np.log(FERRARI['Close'] / FERRARI['Open'])\n",
    "FERRARI['log_close_open_square'] = FERRARI['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_FERRARI = np.sqrt((1/(2*FERRARI.shape[0]))*\n",
    "                       np.sum(FERRARI['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/FERRARI.shape[0])*\n",
    "                              FERRARI['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "TSLA['log_high_low'] = np.log(TSLA['High'] / TSLA['Low'])\n",
    "TSLA['log_high_low_square'] = TSLA['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "TSLA['log_close_open'] = np.log(TSLA['Close'] / TSLA['Open'])\n",
    "TSLA['log_close_open_square'] = TSLA['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_TSLA = np.sqrt((1/(2*TSLA.shape[0]))*\n",
    "                       np.sum(TSLA['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/TSLA.shape[0])*\n",
    "                              TSLA['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "TOYOTA['log_high_low'] = np.log(TOYOTA['High'] / TOYOTA['Low'])\n",
    "TOYOTA['log_high_low_square'] = TOYOTA['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "TOYOTA['log_close_open'] = np.log(TOYOTA['Close'] / TOYOTA['Open'])\n",
    "TOYOTA['log_close_open_square'] = TOYOTA['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_TOYOTA = np.sqrt((1/(2*TOYOTA.shape[0]))*\n",
    "                       np.sum(TOYOTA['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/TOYOTA.shape[0])*\n",
    "                              TOYOTA['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "FIAT['log_high_low'] = np.log(FIAT['High'] / FIAT['Low'])\n",
    "FIAT['log_high_low_square'] = FIAT['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "FIAT['log_close_open'] = np.log(FIAT['Close'] / FIAT['Open'])\n",
    "FIAT['log_close_open_square'] = FIAT['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_FIAT = np.sqrt((1/(2*FIAT.shape[0]))*\n",
    "                       np.sum(FIAT['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/FIAT.shape[0])*\n",
    "                              FIAT['log_close_open_square']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX:  0.025\n",
      "AAPL:  0.0163\n",
      "DIS:  0.0157\n",
      "SPOT:  0.0312\n",
      "AMZN:  0.0178\n",
      "\n",
      "Mean Volatility Streaming Services =  0.021\n",
      "\n",
      "FORD:  0.02\n",
      "FERRARI:  0.0154\n",
      "TSLA:  0.033\n",
      "TOYOTA:  0.0081\n",
      "FIAT:  0.0189\n",
      "Mean Volatility Car Manufacturers =  0.019\n"
     ]
    }
   ],
   "source": [
    "## Garman Klass for streaming services\n",
    "print('NFLX: ',round(Garman_Klass_NFLX,4))\n",
    "print('AAPL: ',round(Garman_Klass_AAPL,4))\n",
    "print('DIS: ',round(Garman_Klass_DIS,4))\n",
    "print('SPOT: ',round(Garman_Klass_SPOT,4))\n",
    "print('AMZN: ',round(Garman_Klass_AMZN,4))\n",
    "print('')\n",
    "\n",
    "## Computing mean for \n",
    "portfolio_streaming_GK = [float(Garman_Klass_NFLX),\n",
    "                              float(Garman_Klass_AAPL),\n",
    "                             float(Garman_Klass_DIS),\n",
    "                             float(Garman_Klass_SPOT),\n",
    "                             float(Garman_Klass_AMZN)]\n",
    "portfolio_streaming_GK\n",
    "adding_str = 0\n",
    "for i in range(len(portfolio_streaming_GK)):\n",
    "    adding_str = adding_str + portfolio_streaming_GK[i]\n",
    "    i = i + 1\n",
    "means_str = adding_str/5\n",
    "\n",
    "print('Mean Volatility Streaming Services = ',round(means_str,3))\n",
    "print('')\n",
    "## Garman Klass for Car Manufacturers\n",
    "print('FORD: ',round(Garman_Klass_FORD,4))\n",
    "print('FERRARI: ',round(Garman_Klass_FERRARI,4))\n",
    "print('TSLA: ',round(Garman_Klass_TSLA,4))\n",
    "print('TOYOTA: ',round(Garman_Klass_TOYOTA,4))\n",
    "print('FIAT: ',round(Garman_Klass_FIAT,4))\n",
    "\n",
    "\n",
    "## Computing mean for \n",
    "portfolio_manufacturers_GK = [float(Garman_Klass_FORD),\n",
    "                              float(Garman_Klass_FERRARI),\n",
    "                             float(Garman_Klass_TSLA),\n",
    "                             float(Garman_Klass_TOYOTA),\n",
    "                             float(Garman_Klass_FIAT)]\n",
    "portfolio_manufacturers_GK\n",
    "adding_mtr = 0\n",
    "for i in range(len(portfolio_manufacturers_GK)):\n",
    "    adding_mtr = adding_mtr + portfolio_manufacturers_GK[i]\n",
    "    i = i + 1\n",
    "means_mtr = adding_mtr/5\n",
    "\n",
    "print('Mean Volatility Car Manufacturers = ',round(means_mtr,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treynor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Portfolio Streaming:  1.1013 Portfolio Manufacturer:  0.7458\n"
     ]
    }
   ],
   "source": [
    "## Importing statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "daily_risk_rate = 0.0008/356\n",
    "## Computing \n",
    "reg_1 = smf.ols(formula = 'modeling_returns ~ Benchmark_tot_return', data = portfolio_streaming ).fit()\n",
    "beta_1 = reg_1.params[1]\n",
    "mu_portfolio_1 = portfolio_streaming['modeling_returns'].mean()\n",
    "treynor_1 = (mu_portfolio_1 - daily_risk_rate)/beta_1\n",
    "\n",
    "reg_2 = smf.ols(formula = 'modeling_returns ~ Benchmark_tot_return', data = portfolio_manufacturers).fit()\n",
    "beta_2 = reg_2.params[1]\n",
    "mu_portfolio_2 = portfolio_manufacturers['modeling_returns'].mean()\n",
    "treynor_2 = (mu_portfolio_2 - daily_risk_rate)/beta_2\n",
    "\n",
    "print('Portfolio Streaming: ',round(treynor_1, 4),'Portfolio Manufacturer: ',round(treynor_2, 4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
