{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Alternative Portfolios<center>\n",
    "    \n",
    "### <center>Suggestions from analysts to client<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will analyze alternative portfolios for our client, based on teh given companies he/she provided us in the beginning of the project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "## Importing yahoo finance library\n",
    "import yfinance as yf\n",
    "\n",
    "## Streaming services stock price data\n",
    "NFLX = yf.download('NFLX',start = '2016-01-01', end = '2020-12-31')\n",
    "AAPL = yf.download('AAPL',start = '2016-01-01', end = '2020-12-31')\n",
    "DIS = yf.download('DIS',start = '2016-04-03', end = '2020-12-31')\n",
    "SPOT = yf.download('SPOT',start = '2016-01-01', end = '2020-12-31')\n",
    "AMZN = yf.download('AMZN',start = '2016-01-01', end = '2020-12-31')\n",
    "\n",
    "## Car manufacturers stock price data\n",
    "FORD = yf.download('F',start = '2016-01-01', end = '2020-12-31')\n",
    "TSLA = yf.download('TSLA',start = '2016-01-01', end = '2020-12-31')\n",
    "TOYOTA = yf.download('TM',start = '2016-01-01', end = '2020-12-31')\n",
    "FERRARI = yf.download('RACE',start = '2016-01-01', end = '2020-12-31')\n",
    "FIAT = yf.download('FCAU',start = '2016-01-01', end = '2020-12-31')\n",
    "\n",
    "# Downloading S&P 500/benchmark stock price data\n",
    "sp = yf.download('^GSPC', start = '2016-01-01', end = '2020-12-31')\n",
    "\n",
    "## Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returns for each stock, into each portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_financial = pd.DataFrame({\n",
    "    'NFLX_tot_return' : NFLX['Adj Close'].pct_change(),\n",
    "    'AAPL_tot_return' : AAPL['Adj Close'].pct_change(),\n",
    "    'DIS_tot_return' : DIS['Adj Close'].pct_change(),\n",
    "    'AMZN_tot_return' : AMZN['Adj Close'].pct_change(),\n",
    "    'FERRARI_tot_return' : FERRARI['Adj Close'].pct_change()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_portfolio = pd.DataFrame({\n",
    "    'FORD_tot_return' : FORD['Adj Close'].pct_change(),\n",
    "    'FERRARI_tot_return' : FERRARI['Adj Close'].pct_change(),\n",
    "    'TSLA_tot_return' : TSLA['Adj Close'].pct_change(),\n",
    "    'TOYOTA_tot_return' : TOYOTA['Adj Close'].pct_change(),\n",
    "    'FIAT_tot_return' : FIAT['Adj Close'].pct_change(),\n",
    "    'NFLX_tot_return' : NFLX['Adj Close'].pct_change(),\n",
    "    'AAPL_tot_return' : AAPL['Adj Close'].pct_change(),\n",
    "    'DIS_tot_return' : DIS['Adj Close'].pct_change(),\n",
    "    'SPOT_tot_return' : SPOT['Adj Close'].pct_change(),\n",
    "    'AMZN_tot_return' : AMZN['Adj Close'].pct_change()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimum variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX:  5.447 %\n",
      "AAPL:  13.571 %\n",
      "DIS:  40.451 %\n",
      "AMZN:  22.225 %\n",
      "RACE:  18.306 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio variance\n",
    "def minimum_variance(x, cov_matrix):\n",
    "    f=float(np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "## Defining the number of stocks\n",
    "n=portfolio_financial.shape[1]\n",
    "\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = portfolio_financial.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_mv = minimize(minimum_variance, x, \n",
    "                     args = (cov_matrix),method = 'SLSQP', \n",
    "                     bounds = bounds, constraints = cons)\n",
    "\n",
    "print('NFLX: ',round(result_mv['x'][0]*100,3),'%')\n",
    "print('AAPL: ',round(result_mv['x'][1]*100,3),'%')\n",
    "print('DIS: ',round(result_mv['x'][2]*100,3),'%')\n",
    "print('AMZN: ',round(result_mv['x'][3]*100,3),'%')\n",
    "print('RACE: ',round(result_mv['x'][4]*100,3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORD 0.0 %\n",
      "FERRARI 1.095 %\n",
      "TSLA 0.0 %\n",
      "TOYOTA 58.449 %\n",
      "FIAT 0.0 %\n",
      "NFLX 3.203 %\n",
      "AAPL 2.107 %\n",
      "DIS 19.979 %\n",
      "SPOT 0.0 %\n",
      "AMZN 15.167 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio variance\n",
    "def minimum_variance(x, cov_matrix):\n",
    "    f=float(np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "## Defining the number of stocks\n",
    "n=full_portfolio.shape[1]\n",
    "\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = full_portfolio.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_mv = minimize(minimum_variance, x, \n",
    "                     args = (cov_matrix),method = 'SLSQP', \n",
    "                     bounds = bounds, constraints = cons)\n",
    "\n",
    "\n",
    "print('FORD',round(result_mv['x'][0]*100,3),'%')\n",
    "print('FERRARI',round(result_mv['x'][1]*100,3),'%')\n",
    "print('TSLA',round(result_mv['x'][2]*100,3),'%')\n",
    "print('TOYOTA',round(result_mv['x'][3]*100,3),'%')\n",
    "print('FIAT',round(result_mv['x'][4]*100,3),'%')\n",
    "print('NFLX',round(result_mv['x'][5]*100,3),'%')\n",
    "print('AAPL',round(result_mv['x'][6]*100,3),'%')\n",
    "print('DIS',round(result_mv['x'][7]*100,3),'%')\n",
    "print('SPOT',round(result_mv['x'][8]*100,3),'%')\n",
    "print('AMZN',round(result_mv['x'][9]*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximized Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NFLX:  8.561 %\n",
      "AAPL:  31.219 %\n",
      "DIS:  0.0 %\n",
      "AMZN:  26.795 %\n",
      "RACE:  33.425 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio Sharpe Ratio\n",
    "def sharpe_ratio(x, cov_matrix, mean_vector, r_f):\n",
    "    f=float(-(x.dot(mean_vector)-r_f)/np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "\n",
    "## Defining the risk free rate\n",
    "daily_risk = 0.0008 / 365\n",
    "\n",
    "n=portfolio_financial.shape[1]\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the mean portfolio_financial\n",
    "mean_vector = np.mean(portfolio_financial, axis=0)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = portfolio_financial.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_Sharpe = minimize(sharpe_ratio, x,\n",
    "                         args=(cov_matrix, mean_vector, daily_risk),\n",
    "                         method = 'SLSQP', bounds = bounds,\n",
    "                         constraints = cons).x\n",
    "\n",
    "print('NFLX: ',round(result_Sharpe[0]*100,3),'%')\n",
    "print('AAPL: ',round(result_Sharpe[1]*100,3),'%')\n",
    "print('DIS: ',round(result_Sharpe[2]*100,3),'%')\n",
    "print('AMZN: ',round(result_Sharpe[3]*100,3),'%')\n",
    "print('RACE: ',round(result_Sharpe[4]*100,3),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FORD 0.0 %\n",
      "FERRARI 27.598 %\n",
      "TSLA 19.807 %\n",
      "TOYOTA 0.0 %\n",
      "FIAT 0.0 %\n",
      "NFLX 4.862 %\n",
      "AAPL 25.427 %\n",
      "DIS 0.0 %\n",
      "SPOT 0.0 %\n",
      "AMZN 22.307 %\n"
     ]
    }
   ],
   "source": [
    "## Defining the portfolio Sharpe Ratio\n",
    "def sharpe_ratio(x, cov_matrix, mean_vector, r_f):\n",
    "    f=float(-(x.dot(mean_vector)-r_f)/np.sqrt(x.dot(cov_matrix).dot(x.T)))\n",
    "    return f\n",
    "\n",
    "## Defining the risk free rate\n",
    "daily_risk = 0.0008 / 365\n",
    "n=full_portfolio.shape[1]\n",
    "## Defining the initial weights\n",
    "x=np.repeat(1/n,n)\n",
    "\n",
    "## Defining the mean portfolio_financial\n",
    "mean_vector = np.mean(full_portfolio, axis=0)\n",
    "\n",
    "## Defining the covariance matrix\n",
    "cov_matrix = full_portfolio.cov()\n",
    "\n",
    "## Defining the matrix of constraints\n",
    "cons = ({'type': 'eq','fun': lambda x: np.sum(x) - 1})\n",
    "bounds = [(0, 1,) for i in range(len(x))]\n",
    "\n",
    "## Solving the optimization problem\n",
    "result_Sharpe = minimize(sharpe_ratio, x,\n",
    "                         args=(cov_matrix, mean_vector, daily_risk),\n",
    "                         method = 'SLSQP', bounds = bounds,\n",
    "                         constraints = cons).x\n",
    "\n",
    "print('FORD',round(result_Sharpe[0]*100,3),'%')\n",
    "print('FERRARI',round(result_Sharpe[1]*100,3),'%')\n",
    "print('TSLA',round(result_Sharpe[2]*100,3),'%')\n",
    "print('TOYOTA',round(result_Sharpe[3]*100,3),'%')\n",
    "print('FIAT',round(result_Sharpe[4]*100,3),'%')\n",
    "print('NFLX',round(result_Sharpe[5]*100,3),'%')\n",
    "print('AAPL',round(result_Sharpe[6]*100,3),'%')\n",
    "print('DIS',round(result_Sharpe[7]*100,3),'%')\n",
    "print('SPOT',round(result_Sharpe[8]*100,3),'%')\n",
    "print('AMZN',round(result_Sharpe[9]*100,3),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cum/gross returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_financial['NFLX_gross_return'] = 1 + portfolio_financial['NFLX_tot_return']\n",
    "portfolio_financial['AAPL_gross_return'] = 1 + portfolio_financial['AAPL_tot_return']\n",
    "portfolio_financial['DIS_gross_return'] = 1 + portfolio_financial['DIS_tot_return']\n",
    "portfolio_financial['AMZN_gross_return'] = 1 + portfolio_financial['AMZN_tot_return']\n",
    "portfolio_financial['FERRARI_gross_return']= 1 + portfolio_financial['FERRARI_tot_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_portfolio['NFLX_gross_return'] = 1 + full_portfolio['NFLX_tot_return']\n",
    "full_portfolio['AAPL_gross_return'] = 1 + full_portfolio['AAPL_tot_return']\n",
    "full_portfolio['DIS_gross_return'] = 1 + full_portfolio['DIS_tot_return']\n",
    "full_portfolio['SPOT_gross_return'] = 1 + full_portfolio['SPOT_tot_return']\n",
    "full_portfolio['AMZN_gross_return'] = 1 + full_portfolio['AMZN_tot_return']\n",
    "full_portfolio['FORD_gross_return'] = 1 + full_portfolio['FORD_tot_return']\n",
    "full_portfolio['FERRARI_gross_return']= 1 + full_portfolio['FERRARI_tot_return']\n",
    "full_portfolio['TSLA_gross_return']= 1 + full_portfolio['TSLA_tot_return']\n",
    "full_portfolio['TOYOTA_gross_return']= 1 +  full_portfolio['TOYOTA_tot_return']\n",
    "full_portfolio['FIAT_gross_return']= 1 +  full_portfolio['FIAT_tot_return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "portfolio_financial['Benchmark_tot_return'] = sp['Adj Close'].pct_change()\n",
    "portfolio_financial = portfolio_financial.dropna()\n",
    "full_portfolio['Benchmark_tot_return'] = sp['Adj Close'].pct_change()\n",
    "full_portfolio = full_portfolio.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "## financial cumulative returns\n",
    "portfolio_financial['NFLX_cum_return'] = portfolio_financial['NFLX_gross_return'].cumprod()\n",
    "portfolio_financial['AAPL_cum_return'] = portfolio_financial['AAPL_gross_return'].cumprod()\n",
    "portfolio_financial['DIS_cum_return'] = portfolio_financial['DIS_gross_return'].cumprod()\n",
    "portfolio_financial['AMZN_cum_return'] = portfolio_financial['AMZN_gross_return'].cumprod()\n",
    "portfolio_financial['FERRARI_cum_return'] = portfolio_financial['FERRARI_gross_return'].cumprod()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_portfolio['NFLX_cum_return'] = full_portfolio['NFLX_gross_return'].cumprod()\n",
    "full_portfolio['AAPL_cum_return'] = full_portfolio['AAPL_gross_return'].cumprod()\n",
    "full_portfolio['DIS_cum_return'] = full_portfolio['DIS_gross_return'].cumprod()\n",
    "full_portfolio['SPOT_cum_return'] = full_portfolio['SPOT_gross_return'].cumprod()\n",
    "full_portfolio['AMZN_cum_return'] = full_portfolio['AMZN_gross_return'].cumprod()\n",
    "full_portfolio['FORD_cum_return'] = full_portfolio['FORD_gross_return'].cumprod()\n",
    "full_portfolio['FERRARI_cum_return'] = full_portfolio['FERRARI_gross_return'].cumprod()\n",
    "full_portfolio['TSLA_cum_return'] = full_portfolio['TSLA_gross_return'].cumprod()\n",
    "full_portfolio['TOYOTA_cum_return'] = full_portfolio['TOYOTA_gross_return'].cumprod()\n",
    "full_portfolio['FIAT_cum_return'] = full_portfolio['FIAT_gross_return'].cumprod()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximized returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of lits you want to generate: 100000\n",
      "NFLX: % 19.99\n",
      "AAPL: % 22.27\n",
      "DIS: % 13.56\n",
      "RACE: % 21.86\n",
      "AMZN: % 22.33\n",
      "\n",
      "financial Portfolio Return: % 493.29\n"
     ]
    }
   ],
   "source": [
    "## Creating empty list\n",
    "random_weights = []\n",
    "\n",
    "## Here we create the number of lists we want to create to simulate differnt portfolios\n",
    "n = int(input('Enter number of lits you want to generate: '))\n",
    "\n",
    "## Creating n lists in the array of lists\n",
    "for p in range(n):\n",
    "    ## Here we create a list with 5 random numbers that sum up to 1.0 (no negative numbers)\n",
    "    random_weights.append(np.random.uniform(low=0.15,high=0.25,size=5))\n",
    "    random_weights[p] /= random_weights[p].sum()\n",
    "    \n",
    "## Here we print the array of lists\n",
    "#print(random_weights)\n",
    "\n",
    "## Creating variable to hold maximum return\n",
    "str_maximum = 0\n",
    "\n",
    "## Variable to hold the list used to generate best performing weights\n",
    "str_weights = 0\n",
    "\n",
    "## New column to hold histoical data with best final performance\n",
    "portfolio_financial['modeling_returns'] = 0\n",
    "\n",
    "## Here we go through the n number of lists in the array of lists\n",
    "for i in range(n):\n",
    "    \n",
    "    ## Here we go through the 5 indexes of each list\n",
    "    financial_return = random_weights[i][0]*portfolio_financial['NFLX_cum_return'] \\\n",
    "    + random_weights[i][1]*portfolio_financial['AAPL_cum_return']\\\n",
    "    + random_weights[i][2]*portfolio_financial['DIS_cum_return']\\\n",
    "    + random_weights[i][3]*portfolio_financial['FERRARI_cum_return']\\\n",
    "    + random_weights[i][4]*portfolio_financial['AMZN_cum_return']\n",
    "    ## Here we print the weights used for each calculation\n",
    "    #print('Weights: %',random_weights[i])\n",
    "    ## Here we return the best performance \n",
    "    if financial_return.tail()[-1] > str_maximum: \n",
    "        str_maximum = financial_return.tail()[-1]    \n",
    "            \n",
    "        ## Adding weights of the maximum value to the weights list\n",
    "        str_weights = random_weights[i]\n",
    "\n",
    "        ## Add data to new data frame column\n",
    "        portfolio_financial['modeling_returns'] = financial_return\n",
    "        \n",
    "    #print('')\n",
    "    ## Here we print the returns result for each list in the array\n",
    "    #print('Return %:',round(financial_return.tail()[-1]*100,2))\n",
    "    #print('')\n",
    "\n",
    "print('NFLX: %', round(str_weights[0]*100,2))\n",
    "print('AAPL: %', round(str_weights[1]*100,2))\n",
    "print('DIS: %', round(str_weights[2]*100,2))\n",
    "print('RACE: %', round(str_weights[3]*100,2))\n",
    "print('AMZN: %', round(str_weights[4]*100,2))\n",
    "print('')\n",
    "print('financial Portfolio Return: %',round(str_maximum*100,2))\n",
    "## Visualize new column\n",
    "##print(portfolio_financial['modeling_returns'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returns per stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return Netflix: $ 100496.21\n",
      "Return Apple: $ 115079.35\n",
      "Return Disney: $ 26383.55\n",
      "Return Ferrari: $ 127664.18\n",
      "Return Amazon: $ 123671.12\n",
      " \n",
      "Sum Financial Return: $ 493294.41\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Return Netflix: $',round(str_weights[0]*portfolio_financial['NFLX_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Apple: $',round(str_weights[1]*portfolio_financial['AAPL_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Disney: $',round(str_weights[2]*portfolio_financial['DIS_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Ferrari: $',round(str_weights[3]*portfolio_financial['FERRARI_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Amazon: $',round(str_weights[4]*portfolio_financial['AMZN_cum_return'].tail()[-1]*100000,2))\n",
    "print(' ')\n",
    "print(print('Sum Financial Return: $',round(str_maximum*100000,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "470.42 %\n"
     ]
    }
   ],
   "source": [
    "portfolio_financial['Weighted_results'] = 0.20*portfolio_financial['NFLX_cum_return'] \\\n",
    "+ 0.20*portfolio_financial['AAPL_cum_return']\\\n",
    "+ 0.20*portfolio_financial['DIS_cum_return']\\\n",
    "+ 0.20*portfolio_financial['FERRARI_cum_return']\\\n",
    "+ 0.20*portfolio_financial['AMZN_cum_return']\n",
    "\n",
    "print(round(portfolio_financial['Weighted_results'] .tail()[-1]*100,2),'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full portfolio weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maximized returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter number of lits you want to generate: 100000\n",
      "NFLX: % 6.88\n",
      "AAPL: % 11.12\n",
      "DIS: % 7.74\n",
      "SPOT: % 14.63\n",
      "AMZN: % 7.09\n",
      "FORD: % 9.06\n",
      "FERRARI: % 9.13\n",
      "TSLA: % 20.28\n",
      "FIAT: % 6.96\n",
      "TOYOTA: % 7.11\n",
      "\n",
      "full Portfolio Return: % 416.92\n"
     ]
    }
   ],
   "source": [
    "## Creating empty list\n",
    "random_weights = []\n",
    "\n",
    "## Here we create the number of lists we want to create to simulate differnt portfolios\n",
    "n = int(input('Enter number of lits you want to generate: '))\n",
    "\n",
    "## Creating n lists in the array of lists\n",
    "for p in range(n):\n",
    "    ## Here we create a list with 10 random numbers that sum up to 1.0 (no negative numbers)\n",
    "    random_weights.append(np.random.uniform(low=0.5,high=0.15,size=10))\n",
    "    random_weights[p] /= random_weights[p].sum()\n",
    "    \n",
    "## Here we print the array of lists\n",
    "#print(random_weights)\n",
    "\n",
    "## Creating variable to hold maximum return\n",
    "full_maximum = 0\n",
    "\n",
    "## Variable to hold the list used to generate best performing weights\n",
    "full_weights = 0\n",
    "\n",
    "## New column to hold histoical data with best final performance\n",
    "portfolio_financial['modeling_returns'] = 0\n",
    "\n",
    "## Here we go through the n number of lists in the array of lists\n",
    "for i in range(n):\n",
    "    \n",
    "    ## Here we go through the 5 indexes of each list\n",
    "    full_return = random_weights[i][0]*full_portfolio['NFLX_cum_return'] \\\n",
    "    + random_weights[i][1]*full_portfolio['AAPL_cum_return']\\\n",
    "    + random_weights[i][2]*full_portfolio['DIS_cum_return']\\\n",
    "    + random_weights[i][3]*full_portfolio['SPOT_cum_return']\\\n",
    "    + random_weights[i][4]*full_portfolio['AMZN_cum_return']\\\n",
    "    + random_weights[i][5]* full_portfolio['FORD_cum_return'] \\\n",
    "    + random_weights[i][6]*full_portfolio['FERRARI_cum_return']\\\n",
    "    + random_weights[i][7]*full_portfolio['TSLA_cum_return']\\\n",
    "    + random_weights[i][8]*full_portfolio['TOYOTA_cum_return']\\\n",
    "    + random_weights[i][9]*full_portfolio['FIAT_cum_return']\n",
    "    \n",
    "    \n",
    "    ## Here we print the weights used for each calculation\n",
    "    #print('Weights: %',random_weights[i])\n",
    "    ## Here we return the best performance \n",
    "    if full_return.tail()[-1] > full_maximum: \n",
    "        full_maximum = full_return.tail()[-1]    \n",
    "            \n",
    "        ## Adding weights of the maximum value to the weights list\n",
    "        full_weights = random_weights[i]\n",
    "\n",
    "        ## Add data to new data frame column\n",
    "        full_portfolio['modeling_returns'] = full_return\n",
    "        \n",
    "    #print('')\n",
    "    ## Here we print the returns result for each list in the array\n",
    "    #print('Return %:',round(financial_return.tail()[-1]*100,2))\n",
    "    #print('')\n",
    "\n",
    "print('NFLX: %', round(full_weights[0]*100,2))\n",
    "print('AAPL: %', round(full_weights[1]*100,2))\n",
    "print('DIS: %', round(full_weights[2]*100,2))\n",
    "print('SPOT: %', round(full_weights[3]*100,2))\n",
    "print('AMZN: %', round(full_weights[4]*100,2))\n",
    "print('FORD: %', round(full_weights[5]*100,2))\n",
    "print('FERRARI: %', round(full_weights[6]*100,2))\n",
    "print('TSLA: %', round(full_weights[7]*100,2))\n",
    "print('FIAT: %', round(full_weights[8]*100,2))\n",
    "print('TOYOTA: %', round(full_weights[9]*100,2))\n",
    "print('')\n",
    "print('full Portfolio Return: %',round(full_maximum*100,2))\n",
    "## Visualize new column\n",
    "#print(portfolio_financial['modeling_returns'].tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returns per stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Return Netflix: $ 12728.81\n",
      "Return Apple: $ 36551.75\n",
      "Return Disney: $ 14511.15\n",
      "Return Spotify: $ 31354.33\n",
      "Return Amazon: $ 16737.08\n",
      "Return Ford: $ 8171.03\n",
      "Return Ferrari: $ 17784.04\n",
      "Return Tesla: $ 263348.26\n",
      "Return Fiat: $ 7230.28\n",
      "Return Toyota: $ 8531.35\n",
      " \n",
      "Sum full Portfolio Return: $ 416924.13\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print('Return Netflix: $',round(full_weights[0]*full_portfolio['NFLX_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Apple: $',round(full_weights[1]*full_portfolio['AAPL_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Disney: $',round(full_weights[2]*full_portfolio['DIS_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Spotify: $',round(full_weights[3]*full_portfolio['SPOT_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Amazon: $',round(full_weights[4]*full_portfolio['AMZN_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Ford: $',round(full_weights[5]*full_portfolio['FORD_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Ferrari: $',round(full_weights[6]*full_portfolio['FERRARI_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Tesla: $',round(full_weights[7]*full_portfolio['TSLA_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Fiat: $',round(full_weights[8]*full_portfolio['FIAT_cum_return'].tail()[-1]*100000,2))\n",
    "print('Return Toyota: $',round(full_weights[9]*full_portfolio['TOYOTA_cum_return'].tail()[-1]*100000,2))\n",
    "print(' ')\n",
    "print(print('Sum full Portfolio Return: $',round(full_maximum*100000,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weighted returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted full portfolio % 295.89\n"
     ]
    }
   ],
   "source": [
    "full_weighted = 0.1*full_portfolio['NFLX_cum_return'] \\\n",
    "    + 0.1*full_portfolio['AAPL_cum_return']\\\n",
    "    + 0.1*full_portfolio['DIS_cum_return']\\\n",
    "    + 0.1*full_portfolio['SPOT_cum_return']\\\n",
    "    + 0.1*full_portfolio['AMZN_cum_return']\\\n",
    "    + 0.1* full_portfolio['FORD_cum_return'] \\\n",
    "    + 0.1*full_portfolio['FERRARI_cum_return']\\\n",
    "    + 0.1*full_portfolio['TSLA_cum_return']\\\n",
    "    + 0.1*full_portfolio['TOYOTA_cum_return']\\\n",
    "    + 0.1*full_portfolio['FIAT_cum_return']\n",
    "print('Weighted full portfolio','%',round(full_weighted.tail()[-1]*100,2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vaR and ES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 5% chance that the portfolio losses will exceed $12002.98 dollars.\n",
      "If the losses exceed this value, there is a 5% chance that the losses will average $18072.43 dollars.\n"
     ]
    }
   ],
   "source": [
    "## Computing the value of the investment\n",
    "NFLX_current_value = str_weights[0]*100000*portfolio_financial['NFLX_cum_return'][-1]\n",
    "AAPL_current_value = str_weights[1]*100000*portfolio_financial['AAPL_cum_return'][-1]\n",
    "DIS_current_value = str_weights[2]*100000*portfolio_financial['DIS_cum_return'][-1]\n",
    "FERRARI_current_value = str_weights[3]*100000*portfolio_financial['FERRARI_cum_return'][-1]\n",
    "AMZN_current_value = str_weights[4]*100000*portfolio_financial['AMZN_cum_return'][-1]\n",
    "\n",
    "\n",
    "## Calculating sim portfolio\n",
    "sim_portfolio_finance = NFLX_current_value*portfolio_financial['NFLX_tot_return'] \\\n",
    "+AAPL_current_value*portfolio_financial['AAPL_tot_return']\\\n",
    "+DIS_current_value*portfolio_financial['DIS_tot_return']\\\n",
    "+FERRARI_current_value*portfolio_financial['FERRARI_tot_return']\\\n",
    "+AMZN_current_value*portfolio_financial['AMZN_tot_return']\n",
    "\n",
    "## Calculating Value at Risk (vaR)\n",
    "vaR_str = np.percentile(sim_portfolio_finance,5)\n",
    "\n",
    "## Calculating ES\n",
    "ES_str = sim_portfolio_finance[sim_portfolio_finance<vaR_str].mean()\n",
    "\n",
    "print('There is a 5% chance that the portfolio losses will exceed ${} dollars.'.format(round(vaR_str*-1,2)))\n",
    "print('If the losses exceed this value, there is a 5% chance that the losses will average ${} dollars.'.format(round(ES_str*-1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 5% chance that the portfolio losses will exceed $11471.06 dollars.\n",
      "If the losses exceed this value, there is a 5% chance that the losses will average $17094.09 dollars.\n"
     ]
    }
   ],
   "source": [
    "## Computing the value of the investment\n",
    "NFLX_current_value = 0.2*100000*portfolio_financial['NFLX_cum_return'][-1]\n",
    "AAPL_current_value = 0.2*100000*portfolio_financial['AAPL_cum_return'][-1]\n",
    "DIS_current_value = 0.2*100000*portfolio_financial['DIS_cum_return'][-1]\n",
    "FERRARI_current_value = 0.2*100000*portfolio_financial['FERRARI_cum_return'][-1]\n",
    "AMZN_current_value = 0.2*100000*portfolio_financial['AMZN_cum_return'][-1]\n",
    "\n",
    "\n",
    "## Calculating sim portfolio\n",
    "sim_portfolio_finance = NFLX_current_value*portfolio_financial['NFLX_tot_return'] \\\n",
    "+AAPL_current_value*portfolio_financial['AAPL_tot_return']\\\n",
    "+DIS_current_value*portfolio_financial['DIS_tot_return']\\\n",
    "+FERRARI_current_value*portfolio_financial['FERRARI_tot_return']\\\n",
    "+AMZN_current_value*portfolio_financial['AMZN_tot_return']\n",
    "\n",
    "## Calculating Value at Risk (vaR)\n",
    "vaR_str = np.percentile(sim_portfolio_finance,5)\n",
    "\n",
    "## Calculating ES\n",
    "ES_str = sim_portfolio_finance[sim_portfolio_finance<vaR_str].mean()\n",
    "\n",
    "print('There is a 5% chance that the portfolio losses will exceed ${} dollars.'.format(round(vaR_str*-1,2)))\n",
    "print('If the losses exceed this value, there is a 5% chance that the losses will average ${} dollars.'.format(round(ES_str*-1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full portfolio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 5% chance that the portfolio losses will exceed $647.13 dollars.\n",
      "If the losses exceed this value, there is a 5% chance that the losses will average $1013.75 dollars.\n"
     ]
    }
   ],
   "source": [
    "NFLX_current_value = full_weights[0]*100000*full_portfolio['NFLX_cum_return'][-1]\n",
    "AAPL_current_value = full_weights[1]*100000*full_portfolio['AAPL_tot_return'][-1]\n",
    "DIS_current_value = full_weights[2]*100000*full_portfolio['DIS_tot_return'][-1]\n",
    "SPOT_current_value = full_weights[3]*100000*full_portfolio['SPOT_tot_return'][-1]\n",
    "AMZN_current_value = full_weights[4]*100000*full_portfolio['AMZN_tot_return'][-1]\n",
    "FORD_current_value = full_weights[5]*100000*full_portfolio['FORD_cum_return'][-1]\n",
    "FERRARI_current_value = full_weights[6]*100000*full_portfolio['FERRARI_tot_return'][-1]\n",
    "TSLA_current_value = full_weights[7]*100000*full_portfolio['TSLA_tot_return'][-1]\n",
    "TOYOTA_current_value = full_weights[8]*100000*full_portfolio['TOYOTA_tot_return'][-1]\n",
    "FIAT_current_value = full_weights[9]*100000*full_portfolio['FIAT_tot_return'][-1]\n",
    "\n",
    "sim_full_port =  NFLX_current_value*full_portfolio['NFLX_tot_return'] \\\n",
    "+AAPL_current_value*full_portfolio['AAPL_tot_return']\\\n",
    "+DIS_current_value*full_portfolio['DIS_tot_return']\\\n",
    "+SPOT_current_value*full_portfolio['SPOT_tot_return']\\\n",
    "+AMZN_current_value*full_portfolio['AMZN_tot_return']\\\n",
    "+FORD_current_value*full_portfolio['FORD_tot_return'] \\\n",
    "+FERRARI_current_value*full_portfolio['FERRARI_tot_return']\\\n",
    "+TSLA_current_value*full_portfolio['TSLA_tot_return']\\\n",
    "+TOYOTA_current_value*full_portfolio['TOYOTA_tot_return']\n",
    "\n",
    "## Calculating Value at Risk (vaR_mtr)\n",
    "vaR_full = np.percentile(sim_full_port,5)\n",
    "\n",
    "## Calculating ES\n",
    "ES_full = sim_full_port[sim_full_port<vaR_full].mean()\n",
    "\n",
    "print('There is a 5% chance that the portfolio losses will exceed ${} dollars.'.format(round(vaR_full*-1,2)))\n",
    "print('If the losses exceed this value, there is a 5% chance that the losses will average ${} dollars.'.format(round(ES_full*-1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equal weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a 5% chance that the portfolio losses will exceed $892.74 dollars.\n",
      "If the losses exceed this value, there is a 5% chance that the losses will average $1332.55 dollars.\n"
     ]
    }
   ],
   "source": [
    "NFLX_current_value = 0.1*100000*full_portfolio['NFLX_cum_return'][-1]\n",
    "AAPL_current_value = 0.1*100000*full_portfolio['AAPL_tot_return'][-1]\n",
    "DIS_current_value = 0.1*100000*full_portfolio['DIS_tot_return'][-1]\n",
    "SPOT_current_value = 0.1*100000*full_portfolio['SPOT_tot_return'][-1]\n",
    "AMZN_current_value = 0.1*100000*full_portfolio['AMZN_tot_return'][-1]\n",
    "FORD_current_value = 0.1*100000*full_portfolio['FORD_cum_return'][-1]\n",
    "FERRARI_current_value = 0.1*100000*full_portfolio['FERRARI_tot_return'][-1]\n",
    "TSLA_current_value = 0.1*100000*full_portfolio['TSLA_tot_return'][-1]\n",
    "TOYOTA_current_value = 0.1*100000*full_portfolio['TOYOTA_tot_return'][-1]\n",
    "FIAT_current_value = 0.1*100000*full_portfolio['FIAT_tot_return'][-1]\n",
    "\n",
    "sim_full_port =  NFLX_current_value*full_portfolio['NFLX_tot_return'] \\\n",
    "+AAPL_current_value*full_portfolio['AAPL_tot_return']\\\n",
    "+DIS_current_value*full_portfolio['DIS_tot_return']\\\n",
    "+SPOT_current_value*full_portfolio['SPOT_tot_return']\\\n",
    "+AMZN_current_value*full_portfolio['AMZN_tot_return']\\\n",
    "+FORD_current_value*full_portfolio['FORD_tot_return'] \\\n",
    "+FERRARI_current_value*full_portfolio['FERRARI_tot_return']\\\n",
    "+TSLA_current_value*full_portfolio['TSLA_tot_return']\\\n",
    "+TOYOTA_current_value*full_portfolio['TOYOTA_tot_return']\n",
    "\n",
    "## Calculating Value at Risk (vaR_mtr)\n",
    "vaR_full = np.percentile(sim_full_port,5)\n",
    "\n",
    "## Calculating ES\n",
    "ES_full = sim_full_port[sim_full_port<vaR_full].mean()\n",
    "\n",
    "print('There is a 5% chance that the portfolio losses will exceed ${} dollars.'.format(round(vaR_full*-1,2)))\n",
    "print('If the losses exceed this value, there is a 5% chance that the losses will average ${} dollars.'.format(round(ES_full*-1,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sharpe Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sharpe values\n",
      " \n",
      "Portfolio_financial:2.447\n",
      "Portfolio_full:2.003\n",
      "Benchmark:0.046\n"
     ]
    }
   ],
   "source": [
    "## Computing the Sharpe Ratio of the portfolio\n",
    "daily_risk_free = 0.0008 / 365\n",
    "mu_portfolio_1 = portfolio_financial['modeling_returns'].mean()\n",
    "sd_portfolio_1 = portfolio_financial['modeling_returns'].std()\n",
    "Sharpe_Portfolio_1 = (mu_portfolio_1 - daily_risk_free) / sd_portfolio_1\n",
    "\n",
    "mu_portfolio_full = full_portfolio['modeling_returns'].mean()\n",
    "sd_portfolio_full = full_portfolio['modeling_returns'].std()\n",
    "Sharpe_Portfolio_full = (mu_portfolio_full - daily_risk_free) / sd_portfolio_full\n",
    "\n",
    "## Computing the Sharpe Ratio of the benchmark\n",
    "mu_benchmark = sp['Adj Close'].pct_change().mean()\n",
    "sd_benchmark = sp['Adj Close'].pct_change().std()\n",
    "Sharpe_Benchmark = (mu_benchmark - daily_risk_free) / sd_benchmark\n",
    "\n",
    "print('Sharpe values')\n",
    "print(' ')\n",
    "print('Portfolio_financial:{}'.format(round(Sharpe_Portfolio_1, 3)))\n",
    "print('Portfolio_full:{}'.format(round(Sharpe_Portfolio_full, 3)))\n",
    "print('Benchmark:{}'.format(round(Sharpe_Benchmark, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Garman Klass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Volatility Streaming Services =  0.018\n",
      "\n",
      "Mean Volatility Full Portfolio =  0.04\n",
      " \n",
      " \n",
      "NFLX:  0.025\n",
      "AAPL:  0.0163\n",
      "DIS:  0.0157\n",
      "SPOT:  0.0312\n",
      "AMZN:  0.0178\n",
      "FORD:  0.02\n",
      "FERRARI:  0.0154\n",
      "TSLA:  0.033\n",
      "TOYOTA:  0.0081\n",
      "FIAT:  0.0189\n"
     ]
    }
   ],
   "source": [
    "## Computing the log(h_t/l_t) and its square\n",
    "NFLX['log_high_low'] = np.log(NFLX['High'] / NFLX['Low'])\n",
    "NFLX['log_high_low_square'] = NFLX['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "NFLX['log_close_open'] = np.log(NFLX['Close'] / NFLX['Open'])\n",
    "NFLX['log_close_open_square'] = NFLX['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_NFLX = np.sqrt((1/(2*NFLX.shape[0]))*\n",
    "                       np.sum(NFLX['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/NFLX.shape[0])*\n",
    "                              NFLX['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "AAPL['log_high_low'] = np.log(AAPL['High'] / AAPL['Low'])\n",
    "AAPL['log_high_low_square'] = AAPL['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "AAPL['log_close_open'] = np.log(AAPL['Close'] / AAPL['Open'])\n",
    "AAPL['log_close_open_square'] = AAPL['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_AAPL = np.sqrt((1/(2*AAPL.shape[0]))*\n",
    "                       np.sum(AAPL['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/AAPL.shape[0])*\n",
    "                              AAPL['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "DIS['log_high_low'] = np.log(DIS['High'] / DIS['Low'])\n",
    "DIS['log_high_low_square'] = DIS['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "DIS['log_close_open'] = np.log(DIS['Close'] / DIS['Open'])\n",
    "DIS['log_close_open_square'] = DIS['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_DIS= np.sqrt((1/(2*DIS.shape[0]))*\n",
    "                       np.sum(DIS['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/DIS.shape[0])*\n",
    "                              DIS['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "SPOT['log_high_low'] = np.log(SPOT['High'] / SPOT['Low'])\n",
    "SPOT['log_high_low_square'] = SPOT['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "SPOT['log_close_open'] = np.log(SPOT['Close'] / SPOT['Open'])\n",
    "SPOT['log_close_open_square'] = SPOT['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_SPOT = np.sqrt((1/(2*SPOT.shape[0]))*\n",
    "                       np.sum(SPOT['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/SPOT.shape[0])*\n",
    "                              SPOT['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "AMZN['log_high_low'] = np.log(AMZN['High'] / AMZN['Low'])\n",
    "AMZN['log_high_low_square'] = AMZN['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "AMZN['log_close_open'] = np.log(AMZN['Close'] / AMZN['Open'])\n",
    "AMZN['log_close_open_square'] = AMZN['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_AMZN = np.sqrt((1/(2*AMZN.shape[0]))*\n",
    "                       np.sum(AMZN['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/AMZN.shape[0])*\n",
    "                              AMZN['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "FORD['log_high_low'] = np.log(FORD['High'] / FORD['Low'])\n",
    "FORD['log_high_low_square'] = FORD['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "FORD['log_close_open'] = np.log(FORD['Close'] / FORD['Open'])\n",
    "FORD['log_close_open_square'] = FORD['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_FORD = np.sqrt((1/(2*FORD.shape[0]))*\n",
    "                       np.sum(FORD['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/FORD.shape[0])*\n",
    "                              FORD['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "FERRARI['log_high_low'] = np.log(FERRARI['High'] / FERRARI['Low'])\n",
    "FERRARI['log_high_low_square'] = FERRARI['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "FERRARI['log_close_open'] = np.log(FERRARI['Close'] / FERRARI['Open'])\n",
    "FERRARI['log_close_open_square'] = FERRARI['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_FERRARI = np.sqrt((1/(2*FERRARI.shape[0]))*\n",
    "                       np.sum(FERRARI['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/FERRARI.shape[0])*\n",
    "                              FERRARI['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "TSLA['log_high_low'] = np.log(TSLA['High'] / TSLA['Low'])\n",
    "TSLA['log_high_low_square'] = TSLA['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "TSLA['log_close_open'] = np.log(TSLA['Close'] / TSLA['Open'])\n",
    "TSLA['log_close_open_square'] = TSLA['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_TSLA = np.sqrt((1/(2*TSLA.shape[0]))*\n",
    "                       np.sum(TSLA['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/TSLA.shape[0])*\n",
    "                              TSLA['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "TOYOTA['log_high_low'] = np.log(TOYOTA['High'] / TOYOTA['Low'])\n",
    "TOYOTA['log_high_low_square'] = TOYOTA['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "TOYOTA['log_close_open'] = np.log(TOYOTA['Close'] / TOYOTA['Open'])\n",
    "TOYOTA['log_close_open_square'] = TOYOTA['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_TOYOTA = np.sqrt((1/(2*TOYOTA.shape[0]))*\n",
    "                       np.sum(TOYOTA['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/TOYOTA.shape[0])*\n",
    "                              TOYOTA['log_close_open_square']))\n",
    "\n",
    "## Computing the log(h_t/l_t) and its square\n",
    "FIAT['log_high_low'] = np.log(FIAT['High'] / FIAT['Low'])\n",
    "FIAT['log_high_low_square'] = FIAT['log_high_low']**2\n",
    "\n",
    "## Computing the log(c_t/o_t) and its square\n",
    "FIAT['log_close_open'] = np.log(FIAT['Close'] / FIAT['Open'])\n",
    "FIAT['log_close_open_square'] = FIAT['log_close_open']**2\n",
    "\n",
    "## Computing the Garman-Klass volatility measure\n",
    "Garman_Klass_FIAT = np.sqrt((1/(2*FIAT.shape[0]))*\n",
    "                       np.sum(FIAT['log_high_low_square'] -\n",
    "                              ((2*np.log(2) - 1)/FIAT.shape[0])*\n",
    "                              FIAT['log_close_open_square']))\n",
    "\n",
    "\n",
    "## Computing mean for \n",
    "financial_portfolio_GK = [float(Garman_Klass_NFLX),\n",
    "                              float(Garman_Klass_AAPL),\n",
    "                             float(Garman_Klass_DIS),\n",
    "                             float(Garman_Klass_FERRARI),\n",
    "                             float(Garman_Klass_AMZN)]\n",
    "\n",
    "adding_str = 0\n",
    "for i in range(len(financial_portfolio_GK)):\n",
    "    adding_str = adding_str + financial_portfolio_GK[i]\n",
    "    i = i + 1\n",
    "means_str = adding_str/5\n",
    "\n",
    "print('Mean Volatility Financial Portfolio = ',round(means_str,3))\n",
    "print('')\n",
    "\n",
    "full_GK = [float(Garman_Klass_NFLX),\n",
    "                             float(Garman_Klass_AAPL),\n",
    "                             float(Garman_Klass_DIS),\n",
    "                             float(Garman_Klass_SPOT),\n",
    "                             float(Garman_Klass_AMZN),\n",
    "                             float(Garman_Klass_FORD),\n",
    "                             float(Garman_Klass_FERRARI),\n",
    "                             float(Garman_Klass_TSLA),\n",
    "                             float(Garman_Klass_TOYOTA),\n",
    "                             float(Garman_Klass_FIAT)]\n",
    "full_GK\n",
    "\n",
    "adding_full = 0\n",
    "for i in range(len(full_GK)):\n",
    "    adding_full = adding_full + full_GK[i]\n",
    "    i = i + 1\n",
    "means_full = adding_full/5\n",
    "print('Mean Volatility Full Portfolio = ',round(means_full,3))\n",
    "print(' ')\n",
    "print(' ')\n",
    "\n",
    "print('NFLX: ',round(Garman_Klass_NFLX,4))\n",
    "print('AAPL: ',round(Garman_Klass_AAPL,4))\n",
    "print('DIS: ',round(Garman_Klass_DIS,4))\n",
    "print('SPOT: ',round(Garman_Klass_SPOT,4))\n",
    "print('AMZN: ',round(Garman_Klass_AMZN,4))\n",
    "print('FORD: ',round(Garman_Klass_FORD,4))\n",
    "print('FERRARI: ',round(Garman_Klass_FERRARI,4))\n",
    "print('TSLA: ',round(Garman_Klass_TSLA,4))\n",
    "print('TOYOTA: ',round(Garman_Klass_TOYOTA,4))\n",
    "print('FIAT: ',round(Garman_Klass_FIAT,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treyor ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\giraf\\Anaconda3\\envs\\Python_and_R\\lib\\site-packages\\ipykernel_launcher.py:8: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-inf"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "daily_risk_rate = 0.0008/356\n",
    "## Computing \n",
    "reg_1 = smf.ols(formula = 'modeling_returns ~ Benchmark_tot_return', data = portfolio_financial).fit()\n",
    "beta_1 = reg_1.params[1]\n",
    "mu_portfolio_1 = portfolio_financial['modeling_returns'].mean()\n",
    "treynor_1 = (mu_portfolio_1 - daily_risk_rate)/beta_1\n",
    "\n",
    "treynor_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.919383913812453"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "daily_risk_rate = 0.0008/356\n",
    "\n",
    "## Computing \n",
    "reg_2 = smf.ols(formula = 'Weighted_results ~ Benchmark_tot_return', data = portfolio_financial).fit()\n",
    "beta_2 = reg_2.params[1]\n",
    "mu_portfolio_2 = portfolio_financial['modeling_returns'].mean()\n",
    "treynor_2 = (mu_portfolio_2 - daily_risk_rate)/beta_2\n",
    "\n",
    "treynor_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8227397781182851"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Importing statsmodels\n",
    "import statsmodels.formula.api as smf\n",
    "daily_risk_rate = 0.0008/356\n",
    "## Computing \n",
    "reg_full = smf.ols(formula = 'modeling_returns ~ Benchmark_tot_return', data = full_portfolio).fit()\n",
    "beta_full = reg_full.params[1]\n",
    "mu_portfolio_full = full_portfolio['modeling_returns'].mean()\n",
    "treynor_full = (mu_portfolio_full - daily_risk_rate)/beta_full\n",
    "\n",
    "treynor_full"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
